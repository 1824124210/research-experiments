恶意软件检测实验报告 (Week 2 Day 2)

作者： [1824124210] 日期： 2025年 11月 项目阶段： 最小可行系统 (MVP) 与 特征工程优化

1. 实验背景与目标

本实验（Week 2 Day 2）的目标是构建一个基于机器学习的恶意软件检测系统的原型（MVP），并解决在实际数据处理中遇到的“数据不平衡”问题，最终通过特征工程提升模型的检测能力。

核心任务：

数据准备： 获取良性与恶意 PE 文件样本。

特征提取： 使用 pefile 提取静态特征（如文件头、节区熵、导入表等）。

模型训练： 使用 RandomForest 训练分类器。

优化迭代： 解决数据不平衡问题，并引入高级特征（如可疑 API 扫描）。

2. 数据集构建历程

实验过程中，数据集经历了三次关键的迭代，这对模型性能产生了决定性影响。

阶段

数据集构成 (良性 : 恶意)

数据来源

备注

阶段 1

3 : 223 (极度不平衡)

本地系统文件 : Malware-Database

初始尝试，良性样本严重不足。

阶段 2

1168 : 550 (约 2:1)

Benign-PE-Dataset : Malware-Database

引入开源良性数据集，修复比例失衡。

阶段 3

1168 : 550 (约 2:1)

同上

数据集保持不变，专注于特征维度的扩展。

3. 特征工程演进

我们从基础的物理特征开始，逐步深入到行为意图的检测。

3.1 基础特征 (阶段 1 & 2)

最初，我们只提取了 8 个基础特征，主要关注文件的“物理属性”：

file_size: 文件大小

number_of_sections: 节区数量

max_section_entropy: 最高节区熵 (检测加壳/加密)

avg_section_entropy: 平均节区熵

writable_executable_sections_count: 可写且可执行 (W+E) 节区数量 (高危特征)

number_of_imports: 导入 DLL 数量

number_of_imported_functions: 导入函数总数

number_of_exports: 导出函数数量

3.2 高级特征 (阶段 3)

为了捕获更隐蔽的恶意软件，我们在阶段 3 增加了 3 个“行为/安全”特征：

suspicious_import_count (可疑 API 计数): 扫描导入表，统计 CreateRemoteThread, WriteProcessMemory, InternetOpen 等 20+ 个高危 API 的调用次数。

aslr_enabled: 是否开启地址空间布局随机化 (ASLR)。良性软件通常开启，恶意软件可能关闭。

has_debug: 是否包含调试信息。恶意软件通常会抹去调试信息以阻碍分析。

4. 实验结果对比与分析

我们在同一测试集上评估了三个阶段的模型性能。

4.1 性能数据表

实验阶段

特征数量

准确率 (Accuracy)

恶意样本召回率 (Recall)

评价

阶段 1 (MVP)

8

98.53% (虚假)

1.00

失败。由于数据极度不平衡，模型“作弊”，将所有样本都预测为恶意。良性样本召回率为 0。

阶段 2 (数据平衡)

8

88.57%

0.79

修正。引入大量良性样本后，模型被迫真正学习特征差异。准确率回归真实水平，但漏报了 21% 的恶意软件。

阶段 3 (特征增强)

11

93.41%

0.89

突破。引入 API 扫描等高级特征后，模型捕获能力大幅提升，漏报率从 21% 降至 11%。

4.2 关键发现 (Insights)

准确率的陷阱： 阶段 1 的 98.53% 准确率是一个典型的“准确率悖论”。在极度不平衡的数据集中，仅看 Accuracy 会产生严重的误导。Classification Report 中的 Precision/Recall 才是真相。

数据质量 > 算法调整： 在阶段 2，我们没有修改模型算法，仅仅通过增加良性数据（平衡数据集），就解决了模型无法识别良性软件的根本问题。

领域知识的威力： 在阶段 3，我们没有增加数据量，而是引入了安全领域的先验知识（可疑 API 黑名单）。这直接导致了恶意样本召回率从 0.79 飙升至 0.89，证明了特征工程的核心价值。

5. 结论与展望

通过本次（Week 2 Day 2）的实验，我们成功构建了一个具备实战能力的恶意软件检测器。

当前状态： 模型在测试集上达到了 93.41% 的准确率和 0.89 的恶意样本召回率。

下一步计划 (Week 3)：

尝试更强大的模型（如 XGBoost 或 LightGBM）以进一步挖掘特征潜力。

分析剩余 11% 被漏报的恶意样本（False Negatives），探索它们是如何逃避检测的（可能是使用了高级加壳或动态加载 API）。

本报告基于 Week 2 Day 2 的实验数据自动生成。
